{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "<a href='http://www.pieriandata.com'> <img src='../Pierian_Data_Logo.png' /></a>\n",
    "___\n",
    "# Question and Answer Chat Bots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data\n",
    "\n",
    "We will be working with the Babi Data Set from Facebook Research.\n",
    "\n",
    "Full Details: https://research.fb.com/downloads/babi/\n",
    "\n",
    "- Jason Weston, Antoine Bordes, Sumit Chopra, Tomas Mikolov, Alexander M. Rush,\n",
    "  \"Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks\",\n",
    "  http://arxiv.org/abs/1502.05698\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"train_qa.txt\", \"rb\") as fp:   # Unpickling\n",
    "    train_data =  pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test_qa.txt\", \"rb\") as fp:   # Unpickling\n",
    "    test_data =  pickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the Format of the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Mary',\n",
       "  'moved',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bathroom',\n",
       "  '.',\n",
       "  'Sandra',\n",
       "  'journeyed',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bedroom',\n",
       "  '.'],\n",
       " ['Is', 'Sandra', 'in', 'the', 'hallway', '?'],\n",
       " 'no')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mary moved to the bathroom . Sandra journeyed to the bedroom .'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(train_data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Is Sandra in the hallway ?'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(train_data[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'no'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Setting up Vocabulary of All Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a set that holds the vocab words\n",
    "vocab = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = test_data + train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for story, question , answer in all_data:\n",
    "    # In case you don't know what a union of sets is:\n",
    "    # https://www.programiz.com/python-programming/methods/set/union\n",
    "    vocab = vocab.union(set(story))\n",
    "    vocab = vocab.union(set(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.add('no')\n",
    "vocab.add('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " '?',\n",
       " 'Daniel',\n",
       " 'Is',\n",
       " 'John',\n",
       " 'Mary',\n",
       " 'Sandra',\n",
       " 'apple',\n",
       " 'back',\n",
       " 'bathroom',\n",
       " 'bedroom',\n",
       " 'discarded',\n",
       " 'down',\n",
       " 'dropped',\n",
       " 'football',\n",
       " 'garden',\n",
       " 'got',\n",
       " 'grabbed',\n",
       " 'hallway',\n",
       " 'in',\n",
       " 'journeyed',\n",
       " 'kitchen',\n",
       " 'left',\n",
       " 'milk',\n",
       " 'moved',\n",
       " 'no',\n",
       " 'office',\n",
       " 'picked',\n",
       " 'put',\n",
       " 'the',\n",
       " 'there',\n",
       " 'to',\n",
       " 'took',\n",
       " 'travelled',\n",
       " 'up',\n",
       " 'went',\n",
       " 'yes'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_len = len(vocab) + 1 #we add an extra space to hold a 0 for Keras's pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_story_len = max([len(data[0]) for data in all_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_story_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_question_len = max([len(data[1]) for data in all_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_question_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " '?',\n",
       " 'Daniel',\n",
       " 'Is',\n",
       " 'John',\n",
       " 'Mary',\n",
       " 'Sandra',\n",
       " 'apple',\n",
       " 'back',\n",
       " 'bathroom',\n",
       " 'bedroom',\n",
       " 'discarded',\n",
       " 'down',\n",
       " 'dropped',\n",
       " 'football',\n",
       " 'garden',\n",
       " 'got',\n",
       " 'grabbed',\n",
       " 'hallway',\n",
       " 'in',\n",
       " 'journeyed',\n",
       " 'kitchen',\n",
       " 'left',\n",
       " 'milk',\n",
       " 'moved',\n",
       " 'no',\n",
       " 'office',\n",
       " 'picked',\n",
       " 'put',\n",
       " 'the',\n",
       " 'there',\n",
       " 'to',\n",
       " 'took',\n",
       " 'travelled',\n",
       " 'up',\n",
       " 'went',\n",
       " 'yes'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reserve 0 for pad_sequences\n",
    "vocab_size = len(vocab) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# integer encode sequences of words\n",
    "tokenizer = Tokenizer(filters=[])\n",
    "tokenizer.fit_on_texts(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'got': 1,\n",
       " 'bedroom': 2,\n",
       " 'garden': 3,\n",
       " 'journeyed': 4,\n",
       " 'daniel': 5,\n",
       " 'grabbed': 6,\n",
       " 'up': 7,\n",
       " '?': 8,\n",
       " 'mary': 9,\n",
       " 'travelled': 10,\n",
       " 'sandra': 11,\n",
       " 'went': 12,\n",
       " 'is': 13,\n",
       " 'down': 14,\n",
       " 'no': 15,\n",
       " 'yes': 16,\n",
       " 'john': 17,\n",
       " 'kitchen': 18,\n",
       " 'in': 19,\n",
       " 'the': 20,\n",
       " 'discarded': 21,\n",
       " 'moved': 22,\n",
       " 'milk': 23,\n",
       " 'took': 24,\n",
       " 'hallway': 25,\n",
       " 'dropped': 26,\n",
       " 'to': 27,\n",
       " 'there': 28,\n",
       " '.': 29,\n",
       " 'football': 30,\n",
       " 'left': 31,\n",
       " 'back': 32,\n",
       " 'office': 33,\n",
       " 'apple': 34,\n",
       " 'bathroom': 35,\n",
       " 'put': 36,\n",
       " 'picked': 37}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_story_text = []\n",
    "train_question_text = []\n",
    "train_answers = []\n",
    "\n",
    "for story,question,answer in train_data:\n",
    "    train_story_text.append(story)\n",
    "    train_question_text.append(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_story_seq = tokenizer.texts_to_sequences(train_story_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_story_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_story_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functionalize Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_stories(data, word_index=tokenizer.word_index, max_story_len=max_story_len,max_question_len=max_question_len):\n",
    "    '''\n",
    "    INPUT: \n",
    "    \n",
    "    data: consisting of Stories,Queries,and Answers\n",
    "    word_index: word index dictionary from tokenizer\n",
    "    max_story_len: the length of the longest story (used for pad_sequences function)\n",
    "    max_question_len: length of the longest question (used for pad_sequences function)\n",
    "\n",
    "\n",
    "    OUTPUT:\n",
    "    \n",
    "    Vectorizes the stories,questions, and answers into padded sequences. We first loop for every story, query , and\n",
    "    answer in the data. Then we convert the raw words to an word index value. Then we append each set to their appropriate\n",
    "    output list. Then once we have converted the words to numbers, we pad the sequences so they are all of equal length.\n",
    "    \n",
    "    Returns this in the form of a tuple (X,Xq,Y) (padded based on max lengths)\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    # X = STORIES\n",
    "    X = []\n",
    "    # Xq = QUERY/QUESTION\n",
    "    Xq = []\n",
    "    # Y = CORRECT ANSWER\n",
    "    Y = []\n",
    "    \n",
    "    \n",
    "    for story, query, answer in data:\n",
    "        \n",
    "        # Grab the word index for every word in story\n",
    "        x = [word_index[word.lower()] for word in story]\n",
    "        # Grab the word index for every word in query\n",
    "        xq = [word_index[word.lower()] for word in query]\n",
    "        \n",
    "        # Grab the Answers (either Yes/No so we don't need to use list comprehension here)\n",
    "        # Index 0 is reserved so we're going to use + 1\n",
    "        y = np.zeros(len(word_index) + 1)\n",
    "        \n",
    "        # Now that y is all zeros and we know its just Yes/No , we can use numpy logic to create this assignment\n",
    "        #\n",
    "        y[word_index[answer]] = 1\n",
    "        \n",
    "        # Append each set of story,query, and answer to their respective holding lists\n",
    "        X.append(x)\n",
    "        Xq.append(xq)\n",
    "        Y.append(y)\n",
    "        \n",
    "    # Finally, pad the sequences based on their max length so the RNN can be trained on uniformly long sequences.\n",
    "        \n",
    "    # RETURN TUPLE FOR UNPACKING\n",
    "    return (pad_sequences(X, maxlen=max_story_len),pad_sequences(Xq, maxlen=max_question_len), np.array(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_train, queries_train, answers_train = vectorize_stories(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_test, queries_test, answers_test = vectorize_stories(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0, ..., 20,  2, 29],\n",
       "       [ 0,  0,  0, ..., 20,  3, 29],\n",
       "       [ 0,  0,  0, ..., 20,  3, 29],\n",
       "       ...,\n",
       "       [ 0,  0,  0, ..., 20, 34, 29],\n",
       "       [ 0,  0,  0, ..., 20,  3, 29],\n",
       "       [ 0,  0,  0, ..., 34, 28, 29]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[13, 17, 19, 20, 18,  8],\n",
       "       [13, 17, 19, 20, 18,  8],\n",
       "       [13, 17, 19, 20,  3,  8],\n",
       "       ...,\n",
       "       [13,  9, 19, 20,  2,  8],\n",
       "       [13, 11, 19, 20,  3,  8],\n",
       "       [13,  9, 19, 20,  3,  8]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0., 503., 497.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(answers_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index['yes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index['no']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Input, Activation, Dense, Permute, Dropout\n",
    "from keras.layers import add, dot, concatenate\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Placeholders for Inputs\n",
    "\n",
    "Recall we technically have two inputs, stories and questions. So we need to use placeholders. `Input()` is used to instantiate a Keras tensor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequence = Input((max_story_len,))\n",
    "question = Input((max_question_len,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Building the Networks\n",
    "\n",
    "To understand why we chose this setup, make sure to read the paper we are using:\n",
    "\n",
    "* Sainbayar Sukhbaatar, Arthur Szlam, Jason Weston, Rob Fergus,\n",
    "  \"End-To-End Memory Networks\",\n",
    "  http://arxiv.org/abs/1503.08895"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoders\n",
    "\n",
    "### Input Encoder m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input gets embedded to a sequence of vectors\n",
    "input_encoder_m = Sequential()\n",
    "input_encoder_m.add(Embedding(input_dim=vocab_size,output_dim=64))\n",
    "input_encoder_m.add(Dropout(0.3))\n",
    "\n",
    "# This encoder will output:\n",
    "# (samples, story_maxlen, embedding_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Encoder c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed the input into a sequence of vectors of size query_maxlen\n",
    "input_encoder_c = Sequential()\n",
    "input_encoder_c.add(Embedding(input_dim=vocab_size,output_dim=max_question_len))\n",
    "input_encoder_c.add(Dropout(0.3))\n",
    "# output: (samples, story_maxlen, query_maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed the question into a sequence of vectors\n",
    "question_encoder = Sequential()\n",
    "question_encoder.add(Embedding(input_dim=vocab_size,\n",
    "                               output_dim=64,\n",
    "                               input_length=max_question_len))\n",
    "question_encoder.add(Dropout(0.3))\n",
    "# output: (samples, query_maxlen, embedding_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode the Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode input sequence and questions (which are indices)\n",
    "# to sequences of dense vectors\n",
    "input_encoded_m = input_encoder_m(input_sequence)\n",
    "input_encoded_c = input_encoder_c(input_sequence)\n",
    "question_encoded = question_encoder(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Use dot product to compute the match between first input vector seq and the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape: `(samples, story_maxlen, query_maxlen)`\n",
    "match = dot([input_encoded_m, question_encoded], axes=(2, 2))\n",
    "match = Activation('softmax')(match)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add this match matrix with the second input vector sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the match matrix with the second input vector sequence\n",
    "response = add([match, input_encoded_c])  # (samples, story_maxlen, query_maxlen)\n",
    "response = Permute((2, 1))(response)  # (samples, query_maxlen, story_maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate the match matrix with the question vector sequence\n",
    "answer = concatenate([response, question_encoded])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'concatenate/concat:0' shape=(None, 6, 220) dtype=float32>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce with RNN (LSTM)\n",
    "answer = LSTM(32)(answer)  # (samples, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regularization with Dropout\n",
    "answer = Dropout(0.5)(answer)\n",
    "answer = Dense(vocab_size)(answer)  # (samples, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we output a probability distribution over the vocabulary\n",
    "answer = Activation('softmax')(answer)\n",
    "\n",
    "# build the final model\n",
    "model = Model([input_sequence, question], answer)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 156)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential (Sequential)         (None, None, 64)     2432        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sequential_2 (Sequential)       (None, 6, 64)        2432        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot (Dot)                       (None, 156, 6)       0           sequential[0][0]                 \n",
      "                                                                 sequential_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 156, 6)       0           dot[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       (None, None, 6)      228         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 156, 6)       0           activation[0][0]                 \n",
      "                                                                 sequential_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "permute (Permute)               (None, 6, 156)       0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 6, 220)       0           permute[0][0]                    \n",
      "                                                                 sequential_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 32)           32384       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 32)           0           lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 38)           1254        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 38)           0           dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 38,730\n",
      "Trainable params: 38,730\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.8611 - accuracy: 0.5038 - val_loss: 0.7040 - val_accuracy: 0.5030\n",
      "Epoch 2/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.7005 - accuracy: 0.4984 - val_loss: 0.6945 - val_accuracy: 0.5030\n",
      "Epoch 3/120\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.6956 - accuracy: 0.4931 - val_loss: 0.6932 - val_accuracy: 0.5030\n",
      "Epoch 4/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.6952 - accuracy: 0.4970 - val_loss: 0.6939 - val_accuracy: 0.5030\n",
      "Epoch 5/120\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.6942 - accuracy: 0.5017 - val_loss: 0.6933 - val_accuracy: 0.4970\n",
      "Epoch 6/120\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.6947 - accuracy: 0.4978 - val_loss: 0.6932 - val_accuracy: 0.4760\n",
      "Epoch 7/120\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.6945 - accuracy: 0.5017 - val_loss: 0.6933 - val_accuracy: 0.4970\n",
      "Epoch 8/120\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.6943 - accuracy: 0.5012 - val_loss: 0.6934 - val_accuracy: 0.5030\n",
      "Epoch 9/120\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.6941 - accuracy: 0.5046 - val_loss: 0.6934 - val_accuracy: 0.5030\n",
      "Epoch 10/120\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.6938 - accuracy: 0.5026 - val_loss: 0.6947 - val_accuracy: 0.5030\n",
      "Epoch 11/120\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.6931 - accuracy: 0.5130 - val_loss: 0.6939 - val_accuracy: 0.4830\n",
      "Epoch 12/120\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.6899 - accuracy: 0.5224 - val_loss: 0.6890 - val_accuracy: 0.5040\n",
      "Epoch 13/120\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.6779 - accuracy: 0.5732 - val_loss: 0.6655 - val_accuracy: 0.6000\n",
      "Epoch 14/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.6511 - accuracy: 0.6239 - val_loss: 0.6359 - val_accuracy: 0.6570\n",
      "Epoch 15/120\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.6355 - accuracy: 0.6464 - val_loss: 0.6254 - val_accuracy: 0.6600\n",
      "Epoch 16/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.6260 - accuracy: 0.6569 - val_loss: 0.6148 - val_accuracy: 0.6740\n",
      "Epoch 17/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.6081 - accuracy: 0.6776 - val_loss: 0.5917 - val_accuracy: 0.6810\n",
      "Epoch 18/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.5680 - accuracy: 0.7137 - val_loss: 0.5317 - val_accuracy: 0.7490\n",
      "Epoch 19/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.5206 - accuracy: 0.7552 - val_loss: 0.5061 - val_accuracy: 0.7720\n",
      "Epoch 20/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.4877 - accuracy: 0.7752 - val_loss: 0.4843 - val_accuracy: 0.7830\n",
      "Epoch 21/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.4661 - accuracy: 0.7899 - val_loss: 0.4560 - val_accuracy: 0.7870\n",
      "Epoch 22/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.4490 - accuracy: 0.8037 - val_loss: 0.4393 - val_accuracy: 0.8120\n",
      "Epoch 23/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.4315 - accuracy: 0.8162 - val_loss: 0.4734 - val_accuracy: 0.8150\n",
      "Epoch 24/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.4231 - accuracy: 0.8157 - val_loss: 0.4288 - val_accuracy: 0.8160\n",
      "Epoch 25/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.4112 - accuracy: 0.8288 - val_loss: 0.4348 - val_accuracy: 0.8040\n",
      "Epoch 26/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.4038 - accuracy: 0.8276 - val_loss: 0.4755 - val_accuracy: 0.8080\n",
      "Epoch 27/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.4016 - accuracy: 0.8305 - val_loss: 0.4162 - val_accuracy: 0.8220\n",
      "Epoch 28/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.3949 - accuracy: 0.8321 - val_loss: 0.4273 - val_accuracy: 0.8170\n",
      "Epoch 29/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.3837 - accuracy: 0.8400 - val_loss: 0.4048 - val_accuracy: 0.8240\n",
      "Epoch 30/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.3851 - accuracy: 0.8408 - val_loss: 0.4067 - val_accuracy: 0.8260\n",
      "Epoch 31/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.3744 - accuracy: 0.8437 - val_loss: 0.4121 - val_accuracy: 0.8210\n",
      "Epoch 32/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.3737 - accuracy: 0.8448 - val_loss: 0.4092 - val_accuracy: 0.8190\n",
      "Epoch 33/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.3747 - accuracy: 0.8404 - val_loss: 0.3922 - val_accuracy: 0.8270\n",
      "Epoch 34/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.3644 - accuracy: 0.8490 - val_loss: 0.3955 - val_accuracy: 0.8300\n",
      "Epoch 35/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.3590 - accuracy: 0.8475 - val_loss: 0.4076 - val_accuracy: 0.8200\n",
      "Epoch 36/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.3532 - accuracy: 0.8505 - val_loss: 0.4002 - val_accuracy: 0.8170\n",
      "Epoch 37/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.3475 - accuracy: 0.8568 - val_loss: 0.4002 - val_accuracy: 0.8260\n",
      "Epoch 38/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.3465 - accuracy: 0.8569 - val_loss: 0.3810 - val_accuracy: 0.8200\n",
      "Epoch 39/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.3410 - accuracy: 0.8571 - val_loss: 0.3874 - val_accuracy: 0.8250\n",
      "Epoch 40/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.3373 - accuracy: 0.8588 - val_loss: 0.4015 - val_accuracy: 0.8220\n",
      "Epoch 41/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.3313 - accuracy: 0.8607 - val_loss: 0.4021 - val_accuracy: 0.8310\n",
      "Epoch 42/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.3312 - accuracy: 0.8586 - val_loss: 0.3825 - val_accuracy: 0.8330\n",
      "Epoch 43/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.3306 - accuracy: 0.8613 - val_loss: 0.3826 - val_accuracy: 0.8330\n",
      "Epoch 44/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.3239 - accuracy: 0.8639 - val_loss: 0.3935 - val_accuracy: 0.8320\n",
      "Epoch 45/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.3212 - accuracy: 0.8684 - val_loss: 0.3818 - val_accuracy: 0.8290\n",
      "Epoch 46/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.3192 - accuracy: 0.8651 - val_loss: 0.3773 - val_accuracy: 0.8320\n",
      "Epoch 47/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.3194 - accuracy: 0.8642 - val_loss: 0.3719 - val_accuracy: 0.8240\n",
      "Epoch 48/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.3139 - accuracy: 0.8672 - val_loss: 0.3687 - val_accuracy: 0.8360\n",
      "Epoch 49/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.3107 - accuracy: 0.8675 - val_loss: 0.3772 - val_accuracy: 0.8230\n",
      "Epoch 50/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.3100 - accuracy: 0.8696 - val_loss: 0.3828 - val_accuracy: 0.8240\n",
      "Epoch 51/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.3091 - accuracy: 0.8667 - val_loss: 0.3892 - val_accuracy: 0.8280\n",
      "Epoch 52/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.3090 - accuracy: 0.8666 - val_loss: 0.3801 - val_accuracy: 0.8230\n",
      "Epoch 53/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.3047 - accuracy: 0.8717 - val_loss: 0.3776 - val_accuracy: 0.8260\n",
      "Epoch 54/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2984 - accuracy: 0.8731 - val_loss: 0.3778 - val_accuracy: 0.8220\n",
      "Epoch 55/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.3026 - accuracy: 0.8703 - val_loss: 0.3785 - val_accuracy: 0.8310\n",
      "Epoch 56/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.3012 - accuracy: 0.8713 - val_loss: 0.3844 - val_accuracy: 0.8350\n",
      "Epoch 57/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2923 - accuracy: 0.8755 - val_loss: 0.3695 - val_accuracy: 0.8310\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2935 - accuracy: 0.8746 - val_loss: 0.3839 - val_accuracy: 0.8330\n",
      "Epoch 59/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2915 - accuracy: 0.8752 - val_loss: 0.3921 - val_accuracy: 0.8240\n",
      "Epoch 60/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2898 - accuracy: 0.8724 - val_loss: 0.3896 - val_accuracy: 0.8250\n",
      "Epoch 61/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2896 - accuracy: 0.8748 - val_loss: 0.3798 - val_accuracy: 0.8340\n",
      "Epoch 62/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2864 - accuracy: 0.8778 - val_loss: 0.3982 - val_accuracy: 0.8240\n",
      "Epoch 63/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2894 - accuracy: 0.8769 - val_loss: 0.3822 - val_accuracy: 0.8300\n",
      "Epoch 64/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2811 - accuracy: 0.8786 - val_loss: 0.4174 - val_accuracy: 0.8320\n",
      "Epoch 65/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2818 - accuracy: 0.8768 - val_loss: 0.3897 - val_accuracy: 0.8350\n",
      "Epoch 66/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2842 - accuracy: 0.8778 - val_loss: 0.3720 - val_accuracy: 0.8330\n",
      "Epoch 67/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2809 - accuracy: 0.8795 - val_loss: 0.3864 - val_accuracy: 0.8300\n",
      "Epoch 68/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2775 - accuracy: 0.8797 - val_loss: 0.3983 - val_accuracy: 0.8290\n",
      "Epoch 69/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2766 - accuracy: 0.8796 - val_loss: 0.3964 - val_accuracy: 0.8160\n",
      "Epoch 70/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2757 - accuracy: 0.8813 - val_loss: 0.3925 - val_accuracy: 0.8200\n",
      "Epoch 71/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2740 - accuracy: 0.8801 - val_loss: 0.3806 - val_accuracy: 0.8280\n",
      "Epoch 72/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2713 - accuracy: 0.8813 - val_loss: 0.3958 - val_accuracy: 0.8290\n",
      "Epoch 73/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2682 - accuracy: 0.8825 - val_loss: 0.4056 - val_accuracy: 0.8310\n",
      "Epoch 74/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2710 - accuracy: 0.8827 - val_loss: 0.4024 - val_accuracy: 0.8240\n",
      "Epoch 75/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2672 - accuracy: 0.8845 - val_loss: 0.4232 - val_accuracy: 0.8300\n",
      "Epoch 76/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2672 - accuracy: 0.8866 - val_loss: 0.3955 - val_accuracy: 0.8280\n",
      "Epoch 77/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2661 - accuracy: 0.8827 - val_loss: 0.3924 - val_accuracy: 0.8290\n",
      "Epoch 78/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2619 - accuracy: 0.8889 - val_loss: 0.3950 - val_accuracy: 0.8280\n",
      "Epoch 79/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2623 - accuracy: 0.8871 - val_loss: 0.4066 - val_accuracy: 0.8260\n",
      "Epoch 80/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2652 - accuracy: 0.8870 - val_loss: 0.3977 - val_accuracy: 0.8240\n",
      "Epoch 81/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2595 - accuracy: 0.8873 - val_loss: 0.4323 - val_accuracy: 0.8230\n",
      "Epoch 82/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2619 - accuracy: 0.8887 - val_loss: 0.4199 - val_accuracy: 0.8330\n",
      "Epoch 83/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2569 - accuracy: 0.8891 - val_loss: 0.4097 - val_accuracy: 0.8320\n",
      "Epoch 84/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2546 - accuracy: 0.8909 - val_loss: 0.4310 - val_accuracy: 0.8290\n",
      "Epoch 85/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2546 - accuracy: 0.8914 - val_loss: 0.4085 - val_accuracy: 0.8330\n",
      "Epoch 86/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2514 - accuracy: 0.8945 - val_loss: 0.4140 - val_accuracy: 0.8290\n",
      "Epoch 87/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2481 - accuracy: 0.8922 - val_loss: 0.4190 - val_accuracy: 0.8380\n",
      "Epoch 88/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2481 - accuracy: 0.8921 - val_loss: 0.4265 - val_accuracy: 0.8350\n",
      "Epoch 89/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2483 - accuracy: 0.8940 - val_loss: 0.4191 - val_accuracy: 0.8350\n",
      "Epoch 90/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2477 - accuracy: 0.8934 - val_loss: 0.4304 - val_accuracy: 0.8320\n",
      "Epoch 91/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2451 - accuracy: 0.8918 - val_loss: 0.4213 - val_accuracy: 0.8260\n",
      "Epoch 92/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2434 - accuracy: 0.8936 - val_loss: 0.4325 - val_accuracy: 0.8280\n",
      "Epoch 93/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2466 - accuracy: 0.8932 - val_loss: 0.4214 - val_accuracy: 0.8280\n",
      "Epoch 94/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2387 - accuracy: 0.8978 - val_loss: 0.4373 - val_accuracy: 0.8330\n",
      "Epoch 95/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2401 - accuracy: 0.8989 - val_loss: 0.4376 - val_accuracy: 0.8340\n",
      "Epoch 96/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2344 - accuracy: 0.8995 - val_loss: 0.4291 - val_accuracy: 0.8290\n",
      "Epoch 97/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2384 - accuracy: 0.8977 - val_loss: 0.4486 - val_accuracy: 0.8310\n",
      "Epoch 98/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2349 - accuracy: 0.9007 - val_loss: 0.4309 - val_accuracy: 0.8330\n",
      "Epoch 99/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2319 - accuracy: 0.9038 - val_loss: 0.4587 - val_accuracy: 0.8290\n",
      "Epoch 100/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2312 - accuracy: 0.9033 - val_loss: 0.4543 - val_accuracy: 0.8240\n",
      "Epoch 101/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2368 - accuracy: 0.8979 - val_loss: 0.4485 - val_accuracy: 0.8230\n",
      "Epoch 102/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2347 - accuracy: 0.8988 - val_loss: 0.4516 - val_accuracy: 0.8320\n",
      "Epoch 103/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2326 - accuracy: 0.9025 - val_loss: 0.4450 - val_accuracy: 0.8290\n",
      "Epoch 104/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2259 - accuracy: 0.9045 - val_loss: 0.4796 - val_accuracy: 0.8310\n",
      "Epoch 105/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2315 - accuracy: 0.8996 - val_loss: 0.4428 - val_accuracy: 0.8250\n",
      "Epoch 106/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2200 - accuracy: 0.9033 - val_loss: 0.4574 - val_accuracy: 0.8240\n",
      "Epoch 107/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2263 - accuracy: 0.9070 - val_loss: 0.4482 - val_accuracy: 0.8230\n",
      "Epoch 108/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2225 - accuracy: 0.9061 - val_loss: 0.4737 - val_accuracy: 0.8220\n",
      "Epoch 109/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2255 - accuracy: 0.9062 - val_loss: 0.4454 - val_accuracy: 0.8300\n",
      "Epoch 110/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2273 - accuracy: 0.9051 - val_loss: 0.4629 - val_accuracy: 0.8310\n",
      "Epoch 111/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2211 - accuracy: 0.9078 - val_loss: 0.4639 - val_accuracy: 0.8320\n",
      "Epoch 112/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2244 - accuracy: 0.9064 - val_loss: 0.4697 - val_accuracy: 0.8230\n",
      "Epoch 113/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2190 - accuracy: 0.9066 - val_loss: 0.4641 - val_accuracy: 0.8180\n",
      "Epoch 114/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2170 - accuracy: 0.9084 - val_loss: 0.4667 - val_accuracy: 0.8280\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2195 - accuracy: 0.9095 - val_loss: 0.4827 - val_accuracy: 0.8280\n",
      "Epoch 116/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2179 - accuracy: 0.9092 - val_loss: 0.4526 - val_accuracy: 0.8280\n",
      "Epoch 117/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2096 - accuracy: 0.9104 - val_loss: 0.4518 - val_accuracy: 0.8280\n",
      "Epoch 118/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2050 - accuracy: 0.9141 - val_loss: 0.4751 - val_accuracy: 0.8280\n",
      "Epoch 119/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2138 - accuracy: 0.9126 - val_loss: 0.4861 - val_accuracy: 0.8370\n",
      "Epoch 120/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2172 - accuracy: 0.9094 - val_loss: 0.4912 - val_accuracy: 0.8280\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "history = model.fit([inputs_train, queries_train], answers_train,batch_size=32,epochs=120,validation_data=([inputs_test, queries_test], answers_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'chatbot_120_epochs.h5'\n",
    "model.save(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Model\n",
    "\n",
    "### Plotting Out Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating on Given Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(filename)\n",
    "pred_results = model.predict(([inputs_test, queries_test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mary',\n",
       " 'got',\n",
       " 'the',\n",
       " 'milk',\n",
       " 'there',\n",
       " '.',\n",
       " 'John',\n",
       " 'moved',\n",
       " 'to',\n",
       " 'the',\n",
       " 'bedroom',\n",
       " '.']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mary got the milk there . John moved to the bedroom .\n"
     ]
    }
   ],
   "source": [
    "story =' '.join(word for word in test_data[0][0])\n",
    "print(story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is John in the kitchen ?\n"
     ]
    }
   ],
   "source": [
    "query = ' '.join(word for word in test_data[0][1])\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Test Answer from Data is: no\n"
     ]
    }
   ],
   "source": [
    "print(\"True Test Answer from Data is:\",test_data[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted answer is:  no\n",
      "Probability of certainty was:  0.99990344\n"
     ]
    }
   ],
   "source": [
    "#Generate prediction from model\n",
    "val_max = np.argmax(pred_results[0])\n",
    "\n",
    "for key, val in tokenizer.word_index.items():\n",
    "    if val == val_max:\n",
    "        k = key\n",
    "\n",
    "print(\"Predicted answer is: \", k)\n",
    "print(\"Probability of certainty was: \", pred_results[0][val_max])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing Your Own Stories and Questions\n",
    "\n",
    "Remember you can only use words from the existing vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " '?',\n",
       " 'Daniel',\n",
       " 'Is',\n",
       " 'John',\n",
       " 'Mary',\n",
       " 'Sandra',\n",
       " 'apple',\n",
       " 'back',\n",
       " 'bathroom',\n",
       " 'bedroom',\n",
       " 'discarded',\n",
       " 'down',\n",
       " 'dropped',\n",
       " 'football',\n",
       " 'garden',\n",
       " 'got',\n",
       " 'grabbed',\n",
       " 'hallway',\n",
       " 'in',\n",
       " 'journeyed',\n",
       " 'kitchen',\n",
       " 'left',\n",
       " 'milk',\n",
       " 'moved',\n",
       " 'no',\n",
       " 'office',\n",
       " 'picked',\n",
       " 'put',\n",
       " 'the',\n",
       " 'there',\n",
       " 'to',\n",
       " 'took',\n",
       " 'travelled',\n",
       " 'up',\n",
       " 'went',\n",
       " 'yes'}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['John',\n",
       " 'left',\n",
       " 'the',\n",
       " 'kitchen',\n",
       " '.',\n",
       " 'Sandra',\n",
       " 'dropped',\n",
       " 'the',\n",
       " 'football',\n",
       " 'in',\n",
       " 'the',\n",
       " 'garden',\n",
       " '.']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note the whitespace of the periods\n",
    "my_story = \"John left the kitchen . Sandra dropped the football in the garden .\"\n",
    "my_story.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_question = \"Is the football in the garden ?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Is', 'the', 'football', 'in', 'the', 'garden', '?']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_question.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata = [(my_story.split(),my_question.split(),'yes')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_story,my_ques,my_ans = vectorize_stories(mydata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_results = model.predict(([ my_story, my_ques]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted answer is:  yes\n",
      "Probability of certainty was:  0.9932569\n"
     ]
    }
   ],
   "source": [
    "#Generate prediction from model\n",
    "val_max = np.argmax(pred_results[0])\n",
    "\n",
    "for key, val in tokenizer.word_index.items():\n",
    "    if val == val_max:\n",
    "        k = key\n",
    "\n",
    "print(\"Predicted answer is: \", k)\n",
    "print(\"Probability of certainty was: \", pred_results[0][val_max])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Great Job!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
